{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6ZSTMafO-AY"
      },
      "source": [
        "# Part 1: Setup & Training\n",
        "This section loads your dataset, fine-tunes the ensemble, and saves the models. If you already have trained models, you can skip to Part 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyp5sA0PO-Aa",
        "outputId": "c5a0a720-f2e3-4e04-b148-b6cdf881c716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install dependencies\n",
        "!pip install transformers torch pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7vnV5dHO-Aa",
        "outputId": "be9b4129-d496-43d8-d89c-7846304172c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load CLIP\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rHssPqiGO-Aa",
        "outputId": "26f8d889-ef14-45ac-9e23-b8ef16cd3a3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   image_id   file_name  score_1  score_2  score_3  score_mean  score_std\n",
              "0          1  img_1.jpg        5        5        5    5.000000    0.00000\n",
              "1          2  img_2.jpg        4        5        4    4.333333    0.57735\n",
              "2          3  img_3.jpg        5        5        5    5.000000    0.00000\n",
              "3          4  img_4.jpg        3        4        4    3.666667    0.57735\n",
              "4          5  img_5.jpg        4        3        3    3.333333    0.57735"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5190fb29-b6b9-4665-89cc-8df01b0de597\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>file_name</th>\n",
              "      <th>score_1</th>\n",
              "      <th>score_2</th>\n",
              "      <th>score_3</th>\n",
              "      <th>score_mean</th>\n",
              "      <th>score_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>img_1.jpg</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>img_2.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>0.57735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>img_3.jpg</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>img_4.jpg</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>0.57735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>img_5.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>0.57735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5190fb29-b6b9-4665-89cc-8df01b0de597')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5190fb29-b6b9-4665-89cc-8df01b0de597 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5190fb29-b6b9-4665-89cc-8df01b0de597');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-beccc12b-9e71-4287-9f1c-7ec6d0419084\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-beccc12b-9e71-4287-9f1c-7ec6d0419084')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-beccc12b-9e71-4287-9f1c-7ec6d0419084 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 114,\n  \"fields\": [\n    {\n      \"column\": \"image_id \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33,\n        \"min\": 1,\n        \"max\": 114,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          81,\n          5,\n          41\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 114,\n        \"samples\": [\n          \"img_81.jpg\",\n          \"img_5.jpg\",\n          \"img_41.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5183672526838738,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          3.0,\n          5.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21888616184055978,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.5773502692,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Load Dataset Labels\n",
        "# Ensure labels.csv exists in your drive path\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/cs441dataset/labels.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gak5KyXuO-Aa",
        "outputId": "bc021c82-3190-4524-d7a5-47aaf2a1a340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [02:04<00:00, 31.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 114 images.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "features = []\n",
        "batch_size = 32\n",
        "base_path = \"/content/drive/MyDrive/cs441dataset/images/\"\n",
        "\n",
        "# Process images in batches\n",
        "for i in tqdm(range(0, len(df), batch_size)):\n",
        "    batch_files = df['file_name'][i : i + batch_size]\n",
        "    batch_images = []\n",
        "\n",
        "    for f in batch_files:\n",
        "        try:\n",
        "            img = Image.open(os.path.join(base_path, f)).convert(\"RGB\")\n",
        "            batch_images.append(img)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {f}: {e}\")\n",
        "\n",
        "    if not batch_images: continue\n",
        "\n",
        "    # Process Batch\n",
        "    inputs = processor(images=batch_images, return_tensors=\"pt\", padding=True).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        batch_features = model.get_image_features(**inputs)\n",
        "        batch_features = F.normalize(batch_features, p=2, dim=1)\n",
        "\n",
        "    for filename, feature in zip(batch_files, batch_features):\n",
        "        features.append((filename, feature.cpu()))\n",
        "\n",
        "print(f\"Processed {len(features)} images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9HgMWc3O-Ab",
        "outputId": "9c527174-2239-48b5-97a9-0c922fea3501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved features to /content/drive/MyDrive/cs441dataset/embeddings_2.pkl\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Save Embeddings\n",
        "save_path = \"/content/drive/MyDrive/cs441dataset/embeddings_2.pkl\"\n",
        "with open(save_path, \"wb\") as f:\n",
        "    pickle.dump(features, f)\n",
        "print(f\"Saved features to {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZVOGq9vO-Ab",
        "outputId": "1593cac6-1dbc-4260-d88d-82002022efe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Ensemble Models...\n",
            "\n",
            "Ridge (Linear)       | Test MSE: 0.9366\n",
            "SVR (Support Vector) | Test MSE: 0.9459\n",
            "Random Forest        | Test MSE: 1.3255\n",
            "MLP (Neural Net)     | Test MSE: 0.5637\n",
            "Classifier (LogReg)  | Test Accuracy: 65.22%\n",
            "\n",
            "All models trained and ready\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge, LogisticRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "\n",
        "# Prepare Data for Scikit-Learn\n",
        "X = np.array([f[1].numpy() for f in features])\n",
        "label_map = dict(zip(df['file_name'], df['score_mean']))\n",
        "y = np.array([label_map[f[0]] for f in features])\n",
        "\n",
        "y_class = np.round(y).astype(int)\n",
        "\n",
        "# Split Data\n",
        "X_train, X_temp, y_train, y_temp, y_train_cls, y_temp_cls = train_test_split(\n",
        "    X, y, y_class, test_size=0.40, random_state=42\n",
        ")\n",
        "X_val, X_test, y_val, y_test, y_val_cls, y_test_cls = train_test_split(\n",
        "    X_temp, y_temp, y_temp_cls, test_size=0.50, random_state=42\n",
        ")\n",
        "\n",
        "# Define Ensemble Models\n",
        "models = {\n",
        "    \"Ridge (Linear)\": Ridge(alpha=1.0),\n",
        "    \"SVR (Support Vector)\": SVR(kernel='rbf', C=1.0, epsilon=0.1),\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
        "    \"MLP (Neural Net)\": MLPRegressor(hidden_layer_sizes=(128, 64), max_iter=1000, random_state=42),\n",
        "    \"Classifier (LogReg)\": LogisticRegression(max_iter=1000, multi_class='multinomial')\n",
        "}\n",
        "\n",
        "trained_models = {}\n",
        "\n",
        "print(\"Training Ensemble Models...\\n\")\n",
        "\n",
        "for name, model_inst in models.items():\n",
        "    if \"Classifier\" in name:\n",
        "        model_inst.fit(X_train, y_train_cls)\n",
        "        preds = model_inst.predict(X_test)\n",
        "        acc = accuracy_score(y_test_cls, preds)\n",
        "        print(f\"{name:20s} | Test Accuracy: {acc:.2%}\")\n",
        "    else:\n",
        "        model_inst.fit(X_train, y_train)\n",
        "        preds = model_inst.predict(X_test)\n",
        "        mse = mean_squared_error(y_test, preds)\n",
        "        print(f\"{name:20s} | Test MSE: {mse:.4f}\")\n",
        "\n",
        "    trained_models[name] = model_inst\n",
        "\n",
        "print(\"\\nAll models trained and ready\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting test results\n",
        "print(\"\\nFinal Test Results, on X_test dataset\\n\")\n",
        "\n",
        "for name, model in trained_models.items():\n",
        "    if \"Classifier\" in name:\n",
        "        test_preds = model.predict(X_test)\n",
        "        test_acc = accuracy_score(y_test_cls, test_preds)\n",
        "        print(f\"{name:20s} | Test Accuracy: {test_acc:.2%}\")\n",
        "    else:\n",
        "        test_preds = model.predict(X_test)\n",
        "        test_mse = mean_squared_error(y_test, test_preds)\n",
        "        print(f\"{name:20s} | Test MSE: {test_mse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdozB02XcmWy",
        "outputId": "1d98780e-37ed-4783-af78-d7330ca9519a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Results, on X_test dataset\n",
            "\n",
            "Ridge (Linear)       | Test MSE: 0.9366\n",
            "SVR (Support Vector) | Test MSE: 0.9459\n",
            "Random Forest        | Test MSE: 1.3255\n",
            "MLP (Neural Net)     | Test MSE: 0.5637\n",
            "Classifier (LogReg)  | Test Accuracy: 65.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Tuning on validation dataset"
      ],
      "metadata": {
        "id": "ipinP7vKzYBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import copy"
      ],
      "metadata": {
        "id": "jvu9aTkbvb9a"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_and_params = {\n",
        "    \"Ridge (Linear)\": {\n",
        "        \"model\": Ridge(),\n",
        "        \"params\": {\"alpha\": [0.01, 0.1, 1.0, 10.0]},\n",
        "        \"task\": \"reg\"\n",
        "    },\n",
        "\n",
        "    \"SVR (Support Vector)\": {\n",
        "        \"model\": SVR(kernel=\"rbf\", gamma=\"scale\"),\n",
        "        \"params\": {\n",
        "            \"C\": [0.5, 1.0, 2.0],\n",
        "            \"epsilon\": [0.1, 0.2]\n",
        "        },\n",
        "        \"task\": \"reg\"\n",
        "    },\n",
        "\n",
        "    \"Random Forest\": {\n",
        "        \"model\": RandomForestRegressor(random_state=42),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [200, 400],      # more trees\n",
        "            \"max_depth\": [10, 20, None],     # safer depth\n",
        "            \"min_samples_leaf\": [2, 4, 6]    # avoid overfitting\n",
        "        },\n",
        "        \"task\": \"reg\"\n",
        "    },\n",
        "\n",
        "    \"MLP (Neural Net)\": {\n",
        "        \"model\": MLPRegressor(\n",
        "            max_iter=500,\n",
        "            random_state=42,\n",
        "            early_stopping=True\n",
        "        ),\n",
        "        \"params\": {\n",
        "            \"hidden_layer_sizes\": [(128,), (128, 64)],  # smaller networks\n",
        "            \"alpha\": [1e-4, 1e-3],\n",
        "            \"learning_rate_init\": [5e-4, 1e-3]\n",
        "        },\n",
        "        \"task\": \"reg\"\n",
        "    },\n",
        "\n",
        "    \"Classifier (LogReg)\": {\n",
        "        \"model\": LogisticRegression(max_iter=1000, multi_class=\"multinomial\"),\n",
        "        \"params\": {\"C\": [0.1, 1.0, 10.0]},\n",
        "        \"task\": \"cls\"\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "# saving baseline models for comparision, so when we hyper parm tune, we dont go below original untuned models\n",
        "trained_models = {}\n",
        "baseline_models = {}\n",
        "\n",
        "for name, cfg in models_and_params.items():\n",
        "    print(f\"--- {name} ---\")\n",
        "\n",
        "    model_class = cfg[\"model\"].__class__\n",
        "    default_params = cfg[\"model\"].get_params()\n",
        "    baseline_models[name] = copy.deepcopy(cfg[\"model\"])  # save baseline\n",
        "\n",
        "    best_score = float(\"inf\") if cfg[\"task\"] == \"reg\" else 0\n",
        "    best_model = None\n",
        "    best_params = None\n",
        "\n",
        "    for params in ParameterGrid(cfg[\"params\"]):\n",
        "        model = model_class(**params)\n",
        "        if cfg[\"task\"] == \"reg\":\n",
        "            model.fit(X_train, y_train)\n",
        "            preds = model.predict(X_val)\n",
        "            score = mean_squared_error(y_val, preds)\n",
        "            if score < best_score:\n",
        "                best_score = score\n",
        "                best_model = model\n",
        "                best_params = params\n",
        "        else:\n",
        "            model.fit(X_train, y_train_cls)\n",
        "            preds = model.predict(X_val)\n",
        "            score = accuracy_score(y_val_cls, preds)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_model = model\n",
        "                best_params = params\n",
        "\n",
        "    # If tuning failed (e.g., worse than baseline), use original default\n",
        "    if best_model is None:\n",
        "        print(\"Tuning did not improve, using default parameters\")\n",
        "        trained_models[name] = baseline_models[name]\n",
        "    else:\n",
        "        trained_models[name] = best_model\n",
        "\n",
        "    print(\"Best params:\", best_params if best_model is not None else default_params)\n",
        "    print(\"Validation score:\", best_score)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL3o7_hYft5N",
        "outputId": "d41761bc-c0bc-42b1-894e-779b8aeb5be7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Ridge (Linear) ---\n",
            "Best params: {'alpha': 0.1}\n",
            "Validation score: 0.5227682097822063\n",
            "\n",
            "--- SVR (Support Vector) ---\n",
            "Best params: {'C': 2.0, 'epsilon': 0.1}\n",
            "Validation score: 0.6349650941756608\n",
            "\n",
            "--- Random Forest ---\n",
            "Best params: {'max_depth': None, 'min_samples_leaf': 6, 'n_estimators': 200}\n",
            "Validation score: 0.7121257711430056\n",
            "\n",
            "--- MLP (Neural Net) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'alpha': 0.001, 'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.0005}\n",
            "Validation score: 0.4510273877112001\n",
            "\n",
            "--- Classifier (LogReg) ---\n",
            "Best params: {'C': 1.0}\n",
            "Validation score: 0.4782608695652174\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "trained_models = {}\n",
        "\n",
        "print(\"\\nHyperparameter Tuning (Validation Set)\\n\")\n",
        "# hyper parameter tunng on validation set only. Look at results, and printed out as well... z\n",
        "\n",
        "for name, cfg in models_and_params.items():\n",
        "    print(f\"--- {name} ---\")\n",
        "\n",
        "    best_score = float(\"inf\") if cfg[\"task\"] == \"reg\" else 0\n",
        "    best_model = None\n",
        "    best_params = None\n",
        "\n",
        "    for params in ParameterGrid(cfg[\"params\"]):\n",
        "        model_class = cfg[\"model\"].__class__\n",
        "        model = model_class(**params)\n",
        "\n",
        "        if cfg[\"task\"] == \"reg\":\n",
        "            model.fit(X_train, y_train)\n",
        "            preds = model.predict(X_val)\n",
        "            score = mean_squared_error(y_val, preds)\n",
        "\n",
        "            if score < best_score:\n",
        "                best_score = score\n",
        "                best_model = model\n",
        "                best_params = params\n",
        "\n",
        "        else:\n",
        "            model.fit(X_train, y_train_cls)\n",
        "            preds = model.predict(X_val)\n",
        "            score = accuracy_score(y_val_cls, preds)\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_model = model\n",
        "                best_params = params\n",
        "\n",
        "    trained_models[name] = best_model\n",
        "    print(\"Best params:\", best_params)\n",
        "    print(\"Validation score:\", best_score)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez6BQSMsft8z",
        "outputId": "f71ea5dc-02ec-4107-d00a-8abdb8045db0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hyperparameter Tuning (Validation Set)\n",
            "\n",
            "--- Ridge (Linear) ---\n",
            "Best params: {'alpha': 0.1}\n",
            "Validation score: 0.5227682097822063\n",
            "\n",
            "--- SVR (Support Vector) ---\n",
            "Best params: {'C': 2.0, 'epsilon': 0.1}\n",
            "Validation score: 0.6349650941756608\n",
            "\n",
            "--- Random Forest ---\n",
            "Best params: {'max_depth': None, 'min_samples_leaf': 2, 'n_estimators': 200}\n",
            "Validation score: 0.7224544482653287\n",
            "\n",
            "--- MLP (Neural Net) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'alpha': 0.001, 'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.001}\n",
            "Validation score: 0.4556207884288928\n",
            "\n",
            "--- Classifier (LogReg) ---\n",
            "Best params: {'C': 1.0}\n",
            "Validation score: 0.4782608695652174\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdOa6yZJzaOd",
        "outputId": "c9f43d2e-2f42-4ef2-a82e-5d13a64b4ecf"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Ridge (Linear)': Ridge(alpha=0.1),\n",
              " 'SVR (Support Vector)': SVR(C=2.0),\n",
              " 'Random Forest': RandomForestRegressor(min_samples_leaf=2, n_estimators=200),\n",
              " 'MLP (Neural Net)': MLPRegressor(alpha=0.001, hidden_layer_sizes=(128, 64)),\n",
              " 'Classifier (LogReg)': LogisticRegression()}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results on Test dataset:"
      ],
      "metadata": {
        "id": "kpAf5XP7zdoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting test results\n",
        "print(\"\\nFinal Test Results, on X_test dataset\\n\")\n",
        "\n",
        "for name, model in trained_models.items():\n",
        "    if \"Classifier\" in name:\n",
        "        test_preds = model.predict(X_test)\n",
        "        test_acc = accuracy_score(y_test_cls, test_preds)\n",
        "        print(f\"{name:20s} | Test Accuracy: {test_acc:.2%}\")\n",
        "    else:\n",
        "        test_preds = model.predict(X_test)\n",
        "        test_mse = mean_squared_error(y_test, test_preds)\n",
        "        print(f\"{name:20s} | Test MSE: {test_mse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X-VR5ztzaRF",
        "outputId": "88083c4c-7a5a-443b-8d4d-0a60f20eb5a2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Results, on X_test dataset\n",
            "\n",
            "Ridge (Linear)       | Test MSE: 0.8664\n",
            "SVR (Support Vector) | Test MSE: 0.8648\n",
            "Random Forest        | Test MSE: 1.2699\n",
            "MLP (Neural Net)     | Test MSE: 0.5671\n",
            "Classifier (LogReg)  | Test Accuracy: 65.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y_e2YNx31akS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graphs + Visuals"
      ],
      "metadata": {
        "id": "W5qmUelG1b2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# model preformance results\n",
        "original = {\n",
        "    \"Ridge\": 0.9366,\n",
        "    \"SVR\": 0.9459,\n",
        "    \"Random Forest\": 1.3255,\n",
        "    \"MLP\": 0.56,\n",
        "    \"LogReg\": 65.22  # accuracy %\n",
        "}\n",
        "\n",
        "# After hyperparameter tuning\n",
        "tuned = {\n",
        "    \"Ridge\": 0.8664,\n",
        "    \"SVR\": 0.8648,\n",
        "    \"Random Forest\": 1.2699,\n",
        "    \"MLP\": 0.56,\n",
        "    \"LogReg\": 65.22  # accuracy %\n",
        "}\n",
        "\n",
        "regressors = [\"Ridge\", \"SVR\", \"Random Forest\", \"MLP\"]\n",
        "classifier = [\"LogReg\"]\n",
        "x = np.arange(len(regressors))\n",
        "width = 0.35\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "ax.bar(x - width/2, [original[m] for m in regressors], width, label='Original')\n",
        "ax.bar(x + width/2, [tuned[m] for m in regressors], width, label='Tuned')\n",
        "\n",
        "ax.set_ylabel(\"Test MSE\")\n",
        "ax.set_title(\"Regression Models: Test MSE Before and After Tuning\")\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(regressors)\n",
        "ax.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "bpJMyWjI2Frw",
        "outputId": "ddd7399c-9c25-488f-d239-93915b5943cb"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qx0tF7381aqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oLVjOfJK1atL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "urpAROyjcmt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXL4ONqYO-Ab",
        "outputId": "f89b4ea2-32af-4286-cc3e-1c261a7d4442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving models to /content/drive/MyDrive/cs441dataset/models-tuned...\n",
            "\n",
            "Saved: model_tunedRidge_Linear.pkl\n",
            "Saved: model_tunedSVR_Support_Vector.pkl\n",
            "Saved: model_tunedRandom_Forest.pkl\n",
            "Saved: model_tunedMLP_Neural_Net.pkl\n",
            "Saved: model_tunedClassifier_LogReg.pkl\n"
          ]
        }
      ],
      "source": [
        "# Save Models\n",
        "save_dir = \"/content/drive/MyDrive/cs441dataset/models-tuned\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Saving models to {save_dir}...\\n\")\n",
        "for name, model_inst in trained_models.items():\n",
        "    safe_name = name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"/\", \"\")\n",
        "    filename = f\"model_tuned{safe_name}.pkl\"\n",
        "    full_path = os.path.join(save_dir, filename)\n",
        "    with open(full_path, \"wb\") as f:\n",
        "        pickle.dump(model_inst, f)\n",
        "    print(f\"Saved: {filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK3MMhnSO-Ab"
      },
      "source": [
        "# Part 2: Inference & Explainability\n",
        "This section allows you to upload new images and get the score + a text-based explanation of *why* it got that score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RK_vbb7BO-Ab",
        "outputId": "efe85c8d-f8c0-4c6b-d89a-e6cc8d8492ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading CLIP model...\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "from PIL import Image, ImageOps\n",
        "import io\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import time\n",
        "import concurrent.futures\n",
        "from transformers import CLIPModel, CLIPProcessor\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Reload CLIP if necessary\n",
        "if 'clip_model' not in locals():\n",
        "    print(\"Reloading CLIP model...\")\n",
        "    clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UUWVFgJO-Ab",
        "outputId": "cb4087d6-adc6-4160-dc6c-1a9cc0add319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding concept bank for explainability...\n",
            "Done! 121 concepts encoded.\n"
          ]
        }
      ],
      "source": [
        "# --- NEW SECTION: EXPLAINABILITY SETUP ---\n",
        "\n",
        "# 1. Define positive and negative concepts for Instagram aesthetics\n",
        "concept_list = [\n",
        "    # --- POSITIVE: COMPOSITION & TECH ---\n",
        "    \"minimalist\", \"flat lay\", \"rule of thirds\", \"symmetry\", \"leading lines\",\n",
        "    \"depth of field\", \"bokeh\", \"sharp focus\", \"clean lines\", \"balanced composition\",\n",
        "    \"negative space\", \"framed subject\", \"cinematic\", \"wide angle\", \"macro detail\",\n",
        "    \"perspective\", \"geometric patterns\", \"high resolution\", \"professional grading\",\n",
        "\n",
        "    # --- POSITIVE: LIGHTING & COLOR ---\n",
        "    \"golden hour\", \"natural light\", \"soft lighting\", \"high contrast\", \"vibrant colors\",\n",
        "    \"pastel aesthetic\", \"neon lights\", \"warm tones\", \"cool tones\", \"monochrome\",\n",
        "    \"black and white\", \"saturated\", \"muted tones\", \"shadow play\", \"sun flare\",\n",
        "    \"dramatic lighting\", \"silhouette\", \"airy\", \"bright and airy\", \"moody lighting\",\n",
        "\n",
        "    # --- POSITIVE: VIBE & AESTHETIC ---\n",
        "    \"luxury\", \"cozy\", \"rustic\", \"vintage\", \"retro\", \"futuristic\",\n",
        "    \"urban\", \"industrial\", \"nature\", \"tropical\", \"beach vibes\",\n",
        "    \"romantic\", \"dreamy\", \"ethereal\", \"energetic\", \"peaceful\",\n",
        "    \"sophisticated\", \"elegant\", \"edgy\", \"whimsical\", \"nostalgic\",\n",
        "    \"clean girl aesthetic\", \"cottagecore\", \"dark academia\", \"y2k aesthetic\",\n",
        "    \"streetwear\", \"old money aesthetic\", \"travel wanderlust\", \"mindfulness\",\n",
        "\n",
        "    # --- SUBJECT SPECIFIC ---\n",
        "    \"portrait\", \"candid moment\", \"group photo\", \"selfie\", \"outfit of the day\",\n",
        "    \"food styling\", \"coffee art\", \"interior design\", \"architecture\", \"landscape\",\n",
        "    \"cityscape\", \"night life\", \"festival\", \"gym fitness\", \"working from home\",\n",
        "    \"plant parent\", \"pet photography\", \"product showcase\", \"texture\",\n",
        "\n",
        "    # --- NEGATIVE: TECHNICAL FLAWS ---\n",
        "    \"blurry\", \"grainy\", \"pixelated\", \"low resolution\", \"out of focus\",\n",
        "    \"motion blur\", \"camera shake\", \"noise\", \"artifacts\", \"chromatic aberration\",\n",
        "    \"lens flare\", \"distorted\", \"overprocessed\", \"unnatural filters\",\n",
        "\n",
        "    # --- NEGATIVE: LIGHTING & COMPOSITION ---\n",
        "    \"dark lighting\", \"underexposed\", \"overexposed\", \"washed out\", \"flash glare\",\n",
        "    \"harsh shadows\", \"poor lighting\", \"yellow cast\", \"blue cast\",\n",
        "    \"cluttered\", \"messy\", \"chaotic background\", \"distracting elements\",\n",
        "    \"crooked horizon\", \"bad framing\", \"awkward angle\", \"crowded\",\n",
        "    \"boring composition\", \"flat lighting\", \"dull colors\"\n",
        "]\n",
        "\n",
        "print(\"Encoding concept bank for explainability...\")\n",
        "\n",
        "# 2. Encode them immediately so they are ready for comparison\n",
        "text_inputs = processor(text=concept_list, return_tensors=\"pt\", padding=True).to(device)\n",
        "with torch.no_grad():\n",
        "    text_features = clip_model.get_text_features(**text_inputs)\n",
        "    text_features = F.normalize(text_features, p=2, dim=1)\n",
        "\n",
        "print(f\"Done! {len(concept_list)} concepts encoded.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai\n",
        "import google.generativeai as genai\n",
        "genai.configure(api_key=\"AIzaSyA5n3Ha038s1LJ2FYmlmhE3h59WAgZgnUs\")"
      ],
      "metadata": {
        "id": "9iKrTZqeQ3E6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Lj8y85dO-Ab"
      },
      "outputs": [],
      "source": [
        "# --- UPDATED HELPER FUNCTIONS ---\n",
        "\n",
        "def get_explanation_data(image_tensor, score):\n",
        "    \"\"\"\n",
        "    1. Finds top matching concepts from CLIP.\n",
        "    2. Sends data to Gemini to get a human-readable explanation.\n",
        "    \"\"\"\n",
        "    # --- 1. CLIP Concept Matching ---\n",
        "    # Calculate Cosine Similarity\n",
        "    sim = (image_tensor.unsqueeze(0) @ text_features.T).squeeze(0)\n",
        "\n",
        "    # Get top 5 matching words for better context\n",
        "    values, indices = sim.topk(5)\n",
        "    top_words = [concept_list[idx] for idx in indices]\n",
        "\n",
        "    # --- 2. Construct Prompt for Gemini ---\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert social media photographer and aesthetic critic.\n",
        "    An AI model has analyzed an image and given it an 'Instagrammable Score'.\n",
        "\n",
        "    Data:\n",
        "    - **Score:** {score:.2f}/5.0\n",
        "    - **Detected Visual Features:** {', '.join(top_words)}\n",
        "\n",
        "    Task:\n",
        "    Write a 2-sentence explanation for the user.\n",
        "    - If the score is high (>4.0), explain why it's great using the detected features.\n",
        "    - If the score is low (<2.5), explain what is hurting the score (e.g. \"The low score is likely due to...\").\n",
        "    - If the score is average, mention the good and bad.\n",
        "\n",
        "    Keep it direct and helpful. Do not mention \"CLIP\" or \"vectors\".\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 3. Call Gemini API ---\n",
        "    try:\n",
        "        model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "        response = model.generate_content(prompt)\n",
        "        explanation = response.text.strip()\n",
        "    except Exception as e:\n",
        "        explanation = f\"Error generating explanation: {str(e)}\"\n",
        "\n",
        "    return top_words, explanation\n",
        "\n",
        "def load_single_image(file_item):\n",
        "    filename, content = file_item\n",
        "    try:\n",
        "        img = Image.open(io.BytesIO(content))\n",
        "        img = ImageOps.exif_transpose(img).convert(\"RGB\")\n",
        "        return (filename, img)\n",
        "    except Exception as e:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "08e38dbcac12452b858d7986b0125366",
            "841563cc410646e489dc8ea6ec3e2b14",
            "4c804e0b7f644f34a3e76584834b71f1",
            "86743e518e5d47ba83c87d2c4b659bb6",
            "9944e47e04914a5098fb04891fd1edae"
          ]
        },
        "id": "TnCVK7AzO-Ab",
        "outputId": "0c694e78-5c89-4781-ac61-86b2f143296c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dashboard Ready! Click the button below to rate images.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, accept='image/*', description='Upload New Image', multiple=True)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08e38dbcac12452b858d7986b0125366"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86743e518e5d47ba83c87d2c4b659bb6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import io\n",
        "from PIL import Image, ImageOps\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import google.generativeai as genai\n",
        "\n",
        "# --- 1. SETUP THE WIDGETS ---\n",
        "# Create a permanent upload button\n",
        "uploader = widgets.FileUpload(\n",
        "    accept='image/*',  # Accept only images\n",
        "    multiple=True,     # Allow multiple files\n",
        "    description='Upload New Image'\n",
        ")\n",
        "\n",
        "# Create an output area where the plots will appear\n",
        "output_area = widgets.Output()\n",
        "\n",
        "# --- 2. DEFINE THE PROCESSING LOGIC ---\n",
        "def process_images(change):\n",
        "    # 'change' contains the details of what was just uploaded\n",
        "    # We look at change['new'] to get the latest files\n",
        "    if not change['new']:\n",
        "        return\n",
        "\n",
        "    # Clear previous results so they don't stack up\n",
        "    output_area.clear_output()\n",
        "\n",
        "    with output_area:\n",
        "        print(\"Processing images... please wait.\")\n",
        "\n",
        "        try:\n",
        "            # Standardize input to a list of dicts\n",
        "            new_files = change['new']\n",
        "\n",
        "            # If it's a dict (ipywidgets 7), convert to list of values\n",
        "            if isinstance(new_files, dict):\n",
        "                file_list = list(new_files.values())\n",
        "            # If it's a tuple/list (ipywidgets 8+), use as is\n",
        "            else:\n",
        "                file_list = new_files\n",
        "\n",
        "            uploaded_files = []\n",
        "\n",
        "            for item in file_list:\n",
        "                # Extract filename and content\n",
        "                # ipywidgets 8 uses 'name' and 'content' (memoryview)\n",
        "                # ipywidgets 7 uses 'metadata'->'name' and 'content' (bytes)\n",
        "\n",
        "                filename = item.get('name') or item.get('metadata', {}).get('name')\n",
        "                content = item.get('content')\n",
        "\n",
        "                # Convert memoryview to bytes if needed\n",
        "                if not isinstance(content, bytes):\n",
        "                    content = content.tobytes()\n",
        "\n",
        "                uploaded_files.append((filename, content))\n",
        "\n",
        "            images, filenames = [], []\n",
        "\n",
        "            # Load Images\n",
        "            for filename, content_bytes in uploaded_files:\n",
        "                try:\n",
        "                    img = Image.open(io.BytesIO(content_bytes))\n",
        "                    img = ImageOps.exif_transpose(img).convert(\"RGB\")\n",
        "                    images.append(img)\n",
        "                    filenames.append(filename)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading {filename}: {e}\")\n",
        "\n",
        "            if not images:\n",
        "                print(\"No valid images found in this upload.\")\n",
        "                return\n",
        "\n",
        "            # --- PROCESS EMBEDDINGS ---\n",
        "            inputs = processor(images=images, return_tensors=\"pt\", padding=True).to(device)\n",
        "            with torch.no_grad():\n",
        "                features = clip_model.get_image_features(**inputs)\n",
        "                features = F.normalize(features, p=2, dim=1)\n",
        "\n",
        "            embeddings_numpy = features.cpu().numpy()\n",
        "            all_results = []\n",
        "\n",
        "            # --- SCORING & EXPLAINING ---\n",
        "            for i in range(len(images)):\n",
        "                vector = embeddings_numpy[i].reshape(1, -1)\n",
        "                image_scores = {}\n",
        "                total_score = 0\n",
        "                count = 0\n",
        "\n",
        "                # Run Regression Models\n",
        "                for name, model in trained_models.items():\n",
        "                    if \"Classifier\" in name: continue\n",
        "                    pred = model.predict(vector)[0]\n",
        "                    pred = max(0.0, min(5.0, pred))\n",
        "                    image_scores[name] = pred\n",
        "                    total_score += pred\n",
        "                    count += 1\n",
        "\n",
        "                avg_score = total_score / count if count > 0 else 0\n",
        "                image_scores[\"Average\"] = avg_score\n",
        "\n",
        "                # Get Gemini Explanation\n",
        "                top_concepts, explanation = get_explanation_data(features[i], avg_score)\n",
        "                image_scores[\"Concepts\"] = top_concepts\n",
        "                image_scores[\"Explanation\"] = explanation\n",
        "                all_results.append(image_scores)\n",
        "\n",
        "            # --- VISUALIZATION ---\n",
        "            cols = 2\n",
        "            rows = math.ceil(len(images) / cols)\n",
        "            plt.figure(figsize=(10 * cols, 8 * rows))\n",
        "\n",
        "            for i, (img, res, fn) in enumerate(zip(images, all_results, filenames)):\n",
        "                ax = plt.subplot(rows, cols, i + 1)\n",
        "                ax.imshow(img)\n",
        "                ax.axis('off')\n",
        "\n",
        "                # Scores\n",
        "                score_text = \"SCORES:\\n\"\n",
        "                for model_name, score in res.items():\n",
        "                    if model_name in [\"Average\", \"Concepts\", \"Explanation\"]: continue\n",
        "                    score_text += f\"• {model_name.split(' ')[0]}: {score:.1f}\\n\"\n",
        "\n",
        "                final_score = res[\"Average\"]\n",
        "                color = 'green' if final_score > 4.0 else ('red' if final_score < 2.5 else 'black')\n",
        "\n",
        "                ax.set_title(f\"{fn}\\nAVG: {final_score:.2f} / 5.0\", color=color, fontsize=16, fontweight='bold')\n",
        "                ax.text(0.02, 0.98, score_text, transform=ax.transAxes,\n",
        "                        fontsize=10, verticalalignment='top',\n",
        "                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "                # Explanation\n",
        "                import textwrap\n",
        "                explanation_text = f\"ANALYSIS:\\n{res['Explanation']}\"\n",
        "                wrapped_text = textwrap.fill(explanation_text, width=60)\n",
        "\n",
        "                ax.text(0.02, 0.02, wrapped_text, transform=ax.transAxes,\n",
        "                        fontsize=11, verticalalignment='bottom', family='monospace',\n",
        "                        bbox=dict(boxstyle='round', facecolor='#f0f0f0', alpha=0.9))\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "# --- 3. ACTIVATE ---\n",
        "# We use 'value' to trigger the event, but we read 'change.new' inside the function\n",
        "uploader.observe(process_images, names='value')\n",
        "\n",
        "print(\"Dashboard Ready! Click the button below to rate images.\")\n",
        "display(uploader)\n",
        "display(output_area)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Ltpxe21RMrW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08e38dbcac12452b858d7986b0125366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 0,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": "image/*",
            "button_style": "",
            "data": [],
            "description": "Upload New Image",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_841563cc410646e489dc8ea6ec3e2b14",
            "metadata": [],
            "multiple": true,
            "style": "IPY_MODEL_4c804e0b7f644f34a3e76584834b71f1"
          }
        },
        "841563cc410646e489dc8ea6ec3e2b14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c804e0b7f644f34a3e76584834b71f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "86743e518e5d47ba83c87d2c4b659bb6": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_9944e47e04914a5098fb04891fd1edae",
            "msg_id": "",
            "outputs": []
          }
        },
        "9944e47e04914a5098fb04891fd1edae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}